{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "import argparse\n",
    "import logging\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "from io import open\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import json\n",
    "\n",
    "from torch.utils.data import (DataLoader, SequentialSampler, RandomSampler, TensorDataset)\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "import ray\n",
    "from ray import tune\n",
    "from ray.tune.schedulers import HyperBandScheduler\n",
    "\n",
    "from models.modeling_bert import QuestionAnswering, Config\n",
    "from utils.optimization import AdamW, WarmupLinearSchedule\n",
    "from utils.tokenization import BertTokenizer\n",
    "from utils.korquad_utils import (read_squad_examples, convert_examples_to_features, RawResult, write_predictions)\n",
    "from debug.evaluate_korquad import evaluate as korquad_eval\n",
    "\n",
    "if sys.version_info[0] == 2:\n",
    "    import cPickle as pickle\n",
    "else:\n",
    "    import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(format='%(asctime)s - %(levelname)s - %(name)s -   %(message)s',\n",
    "                    datefmt='%m/%d/%Y %H:%M:%S',\n",
    "                    level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-06-18 00:26:53,456\tINFO resource_spec.py:212 -- Starting Ray with 16.85 GiB memory available for workers and up to 8.43 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n",
      "2020-06-18 00:26:53,779\tINFO services.py:1170 -- View the Ray dashboard at \u001b[1m\u001b[32m127.0.0.1:8265\u001b[39m\u001b[22m\n",
      "2020-06-18 00:26:53,783\tWARNING services.py:1494 -- WARNING: The object store is using /tmp instead of /dev/shm because /dev/shm has only 67108864 bytes available. This may slow down performance! You may be able to free up space by deleting files in /dev/shm or terminating any running plasma_store_server processes. If you are inside a Docker container, you may need to pass an argument with the flag '--shm-size' to 'docker run'.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'node_ip_address': '172.17.0.2',\n",
       " 'raylet_ip_address': '172.17.0.2',\n",
       " 'redis_address': '172.17.0.2:12362',\n",
       " 'object_store_address': '/tmp/ray/session_2020-06-18_00-26-53_455071_12584/sockets/plasma_store',\n",
       " 'raylet_socket_name': '/tmp/ray/session_2020-06-18_00-26-53_455071_12584/sockets/raylet',\n",
       " 'webui_url': '127.0.0.1:8265',\n",
       " 'session_dir': '/tmp/ray/session_2020-06-18_00-26-53_455071_12584'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ray import tune\n",
    "from ray.tune import track\n",
    "from ray.tune.schedulers import HyperBandScheduler\n",
    "from ray.tune.suggest.bayesopt import BayesOptSearch\n",
    "\n",
    "\n",
    "ray.shutdown()\n",
    "ray.init(local_mode=True, webui_host='127.0.0.1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_space = {\n",
    "    \"max_seq_length\": 512,\n",
    "    \"doc_stride\": 128,\n",
    "    \"max_query_length\": tune.sample_from(lambda _: int(np.random.uniform(50, 100))), #tune.uniform(50, 100),\n",
    "    \"train_batch_size\": 32,\n",
    "    \"learning_rate\": tune.loguniform(5e-4, 5e-7, 10),\n",
    "    \"num_train_epochs\": 4,\n",
    "    \"max_grad_norm\": 1.0,\n",
    "    \"adam_epsilon\": 1e-6,\n",
    "    \"warmup_proportion\": 0.1,\n",
    "    \"n_best_size\": tune.sample_from(lambda _: int(np.random.uniform(50, 100))), #tune.uniform(50, 100),\n",
    "    \"max_answer_length\": tune.sample_from(lambda _: int(np.random.uniform(12, 25))), #tune.uniform(12, 25), \n",
    "    \"seed\": tune.sample_from(lambda _: int(np.random.uniform(1e+6, 1e+8)))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_cache_examples(predict_file, max_seq_length, doc_stride, max_query_length, tokenizer):\n",
    "    # Load data features from cache or dataset file\n",
    "    examples = read_squad_examples(input_file=predict_file,\n",
    "                                   is_training=False,\n",
    "                                   version_2_with_negative=False)\n",
    "    \n",
    "    features = convert_examples_to_features(examples=examples,\n",
    "                                            tokenizer=tokenizer,\n",
    "                                            max_seq_length=max_seq_length,\n",
    "                                            doc_stride=doc_stride,\n",
    "                                            max_query_length=max_query_length,\n",
    "                                            is_training=False)\n",
    "    return examples, features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(predict_file, batch_size, device, output_dir, n_best_size, max_answer_length, model, eval_examples, eval_features):\n",
    "    \"\"\" Eval \"\"\"\n",
    "    all_input_ids = torch.tensor([f.input_ids for f in eval_features], dtype=torch.long)\n",
    "    all_input_mask = torch.tensor([f.input_mask for f in eval_features], dtype=torch.long)\n",
    "    all_segment_ids = torch.tensor([f.segment_ids for f in eval_features], dtype=torch.long)\n",
    "    all_example_index = torch.arange(all_input_ids.size(0), dtype=torch.long)\n",
    "    dataset = TensorDataset(all_input_ids, all_input_mask, all_segment_ids, all_example_index)\n",
    "    sampler = SequentialSampler(dataset)\n",
    "    dataloader = DataLoader(dataset, sampler=sampler, batch_size=batch_size)\n",
    "\n",
    "    logger.info(\"***** Evaluating *****\")\n",
    "    logger.info(\"  Num features = %d\", len(dataset))\n",
    "    logger.info(\"  Batch size = %d\", batch_size)\n",
    "\n",
    "    model.eval()\n",
    "    all_results = []\n",
    "#     set_seed(args)  # Added here for reproductibility (even between python 2 and 3)\n",
    "    logger.info(\"Start evaluating!\")\n",
    "    for input_ids, input_mask, segment_ids, example_indices in tqdm(dataloader, desc=\"Evaluating\"):\n",
    "        input_ids = input_ids.to(device)\n",
    "        input_mask = input_mask.to(device)\n",
    "        segment_ids = segment_ids.to(device)\n",
    "        with torch.no_grad():\n",
    "            batch_start_logits, batch_end_logits = model(input_ids, segment_ids, input_mask)\n",
    "        for i, example_index in enumerate(example_indices):\n",
    "            start_logits = batch_start_logits[i].detach().cpu().tolist()\n",
    "            end_logits = batch_end_logits[i].detach().cpu().tolist()\n",
    "            eval_feature = eval_features[example_index.item()]\n",
    "            unique_id = int(eval_feature.unique_id)\n",
    "            all_results.append(RawResult(unique_id=unique_id,\n",
    "                                         start_logits=start_logits,\n",
    "                                         end_logits=end_logits))\n",
    "    output_prediction_file = os.path.join(output_dir, \"predictions.json\")\n",
    "    output_nbest_file = os.path.join(output_dir, \"nbest_predictions.json\")\n",
    "    write_predictions(eval_examples, eval_features, all_results,\n",
    "                      n_best_size, max_answer_length,\n",
    "                      False, output_prediction_file, output_nbest_file,\n",
    "                      None, False, False, 0.0)\n",
    "\n",
    "    expected_version = 'KorQuAD_v1.0'\n",
    "    with open(predict_file) as dataset_file:\n",
    "        dataset_json = json.load(dataset_file)\n",
    "        read_version = \"_\".join(dataset_json['version'].split(\"_\")[:-1])\n",
    "        if (read_version != expected_version):\n",
    "            logger.info('Evaluation expects ' + expected_version + ', but got dataset with ' + read_version, file=sys.stderr)\n",
    "        dataset = dataset_json['data']\n",
    "    with open(os.path.join(output_dir, \"predictions.json\")) as prediction_file:\n",
    "        predictions = json.load(prediction_file)\n",
    "    _eval = korquad_eval(dataset, predictions)\n",
    "    logger.info(json.dumps(_eval))\n",
    "\n",
    "    return _eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_korquad(train_config):\n",
    "    \n",
    "    # setup\n",
    "    basepath = '/jupyterhome/enpline_bert_competition/korquad-challenge/src'\n",
    "        \n",
    "    logger.info(\"train_config : %s\" % str(train_config))\n",
    "\n",
    "    output_dir='output'\n",
    "    checkpoint=os.path.join(basepath,'data/bert_small_ckpt.bin')\n",
    "    model_config=os.path.join(basepath,'data/bert_small.json')\n",
    "    vocab_file=os.path.join(basepath,'data/ko_vocab_32k.txt')\n",
    "    train_file=os.path.join(basepath, 'data/KorQuAD_v1.0_train.json')\n",
    "    predict_file=os.path.join(basepath, 'data/KorQuAD_v1.0_dev.json')\n",
    "        \n",
    "    \n",
    "    null_score_diff_threshold = 0.0\n",
    "    no_cuda = False\n",
    "    verbose_logging = False\n",
    "    fp16 = True\n",
    "    fp16_opt_level = 'O2' \n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    n_gpu = torch.cuda.device_count()\n",
    "    print(\"device: {} n_gpu: {}, 16-bits training: {}\".format(device, n_gpu, fp16))\n",
    "\n",
    "    random.seed(train_config['seed'])\n",
    "    np.random.seed(train_config['seed'])\n",
    "    torch.manual_seed(train_config['seed'])\n",
    "    if n_gpu > 0:\n",
    "        torch.cuda.manual_seed_all(train_config['seed'])\n",
    "\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    tokenizer = BertTokenizer(vocab_file, max_len=train_config['max_seq_length'], do_basic_tokenize=True)\n",
    "    \n",
    "    # Prepare model\n",
    "    config = Config.from_json_file(model_config)\n",
    "    model = QuestionAnswering(config)\n",
    "    model.bert.load_state_dict(torch.load(checkpoint))\n",
    "    num_params = count_parameters(model)\n",
    "    logger.info(\"Total Parameter: %d\" % num_params)\n",
    "    logger.info(\"Hyper-parameters: %s\" % str(train_config))\n",
    "    paramfile_path = os.path.join(output_dir, 'hyperparameters.txt')\n",
    "    \n",
    "    with open(paramfile_path, \"w\") as paramfile:\n",
    "        logger.info(\"writing hyperparameters at\",paramfile_path)\n",
    "        paramfile.write(\"%s\" % str(train_config))\n",
    "\n",
    "    model.to(device)\n",
    "\n",
    "    cached_train_features_file = train_file + '_{0}_{1}_{2}'.format(str(train_config['max_seq_length']), str(train_config['doc_stride']),\n",
    "                                                                         str(train_config['max_query_length']))\n",
    "    train_examples = read_squad_examples(input_file=train_file, is_training=True, version_2_with_negative=False)\n",
    "    \n",
    "    try:\n",
    "        with open(cached_train_features_file, \"rb\") as reader:\n",
    "            train_features = pickle.load(reader)\n",
    "    except:\n",
    "        train_features = convert_examples_to_features(\n",
    "            examples=train_examples,\n",
    "            tokenizer=tokenizer,\n",
    "            max_seq_length=train_config['max_seq_length'],\n",
    "            doc_stride=train_config['doc_stride'],\n",
    "            max_query_length=train_config['max_query_length'],\n",
    "            is_training=True)\n",
    "        logger.info(\"  Saving train features into cached file %s\", cached_train_features_file)\n",
    "        with open(cached_train_features_file, \"wb\") as writer:\n",
    "            pickle.dump(train_features, writer)\n",
    "\n",
    "    num_train_optimization_steps = int(len(train_features) / train_config['train_batch_size']) * train_config['num_train_epochs']\n",
    "\n",
    "    # Prepare optimizer\n",
    "    param_optimizer = list(model.named_parameters())\n",
    "    no_decay = ['bias', 'LayerNorm.weight']\n",
    "    optimizer_grouped_parameters = [\n",
    "        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
    "         'weight_decay': 0.01},\n",
    "        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "    ]\n",
    "\n",
    "    optimizer = AdamW(optimizer_grouped_parameters,\n",
    "                      lr=train_config['learning_rate'],\n",
    "                      eps=train_config['adam_epsilon'])\n",
    "    scheduler = WarmupLinearSchedule(optimizer,\n",
    "                                     warmup_steps=num_train_optimization_steps*0.1,\n",
    "                                     t_total=num_train_optimization_steps)\n",
    "\n",
    "    if fp16:\n",
    "        try:\n",
    "            from apex import amp\n",
    "        except ImportError:\n",
    "            raise ImportError(\n",
    "                \"Please install apex from https://www.github.com/nvidia/apex to use distributed and fp16 training.\")\n",
    "        model, optimizer = amp.initialize(model, optimizer, opt_level=fp16_opt_level)\n",
    "\n",
    "    logger.info(\"***** Running training *****\")\n",
    "    logger.info(\"  Num orig examples = %d\", len(train_examples))\n",
    "    logger.info(\"  Num split examples = %d\", len(train_features))\n",
    "    logger.info(\"  Batch size = %d\", train_config['train_batch_size'])\n",
    "    logger.info(\"  Num steps = %d\", num_train_optimization_steps)\n",
    "    num_train_step = num_train_optimization_steps\n",
    "\n",
    "    all_input_ids = torch.tensor([f.input_ids for f in train_features], dtype=torch.long)\n",
    "    all_input_mask = torch.tensor([f.input_mask for f in train_features], dtype=torch.long)\n",
    "    all_segment_ids = torch.tensor([f.segment_ids for f in train_features], dtype=torch.long)\n",
    "    all_start_positions = torch.tensor([f.start_position for f in train_features], dtype=torch.long)\n",
    "    all_end_positions = torch.tensor([f.end_position for f in train_features], dtype=torch.long)\n",
    "    train_data = TensorDataset(all_input_ids, all_input_mask, all_segment_ids,\n",
    "                               all_start_positions, all_end_positions)\n",
    "\n",
    "    train_sampler = RandomSampler(train_data)\n",
    "    train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=train_config['train_batch_size'])\n",
    "\n",
    "    model.train()\n",
    "    global_step = 0\n",
    "    epoch = 0\n",
    "    \n",
    "    output_model_file = ''\n",
    "    \n",
    "    # training\n",
    "#     for epoch_idx in trange(int(train_config['num_train_epochs'])):\n",
    "#         iter_bar = tqdm(train_dataloader, desc=\"Train(XX Epoch) Step(XX/XX) (Mean loss=X.X) (loss=X.X)\")\n",
    "\n",
    "    for epoch_idx in range(int(train_config['num_train_epochs'])):\n",
    "        tr_step, total_loss, mean_loss = 0, 0., 0.\n",
    "        for step, batch in enumerate(train_dataloader):\n",
    "            if n_gpu == 1:\n",
    "                batch = tuple(t.to(device) for t in batch)  # multi-gpu does scattering it-self\n",
    "            input_ids, input_mask, segment_ids, start_positions, end_positions = batch\n",
    "            loss = model(input_ids, segment_ids, input_mask, start_positions, end_positions)\n",
    "            if n_gpu > 1:\n",
    "                loss = loss.mean()  # mean() to average on multi-gpu.\n",
    "            if fp16:\n",
    "                with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
    "                    scaled_loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(amp.master_params(optimizer), train_config['max_grad_norm'])\n",
    "            else:\n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), train_config['max_grad_norm'])\n",
    "\n",
    "            scheduler.step()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            global_step += 1\n",
    "            tr_step += 1\n",
    "            total_loss += loss\n",
    "            mean_loss = total_loss / tr_step\n",
    "#             iter_bar.set_description(\"Train Step(%d / %d) (Mean loss=%5.5f) (loss=%5.5f)\" %\n",
    "#                                      (global_step, num_train_step, mean_loss, loss.item()))\n",
    "\n",
    "            epoch += 1 \n",
    "            \n",
    "    logger.info(\"** ** * Saving file * ** **\")  \n",
    "    model_checkpoint = \"korquad_%d.bin\" % (epoch)\n",
    "    logger.info(model_checkpoint)\n",
    "        \n",
    "    #save the last model\n",
    "    output_model_file = os.path.join(output_dir, model_checkpoint)\n",
    "    if n_gpu > 1:\n",
    "        torch.save(model.module.state_dict(), output_model_file)\n",
    "    else:\n",
    "        torch.save(model.state_dict(), output_model_file)\n",
    "      \n",
    "    # Evaluate with final model\n",
    "    examples, features = load_and_cache_examples(predict_file, train_config['max_seq_length'], train_config['doc_stride'], \n",
    "                                                 train_config['max_query_length'], tokenizer)\n",
    "    eval = evaluate(predict_file=predict_file, batch_size=16, device=device, output_dir=output_dir, n_best_size=train_config['n_best_size'], max_answer_length=train_config['max_answer_length'],\n",
    "             model=model, eval_examples=examples, eval_features=features)\n",
    "    \n",
    "    logger.info(\"-\" * 16, 'evaltion', \"-\" *  16)\n",
    "    logger.info(eval)\n",
    "\n",
    "    track.log(f1 = eval['f1'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis = tune.run(train_korquad, config=search_space, scheduler=HyperBandScheduler(metric='f1', mode='max'), resources_per_trial={'gpu':1}, fail_fast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = analysis.trial_dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ax = None\n",
    "# for d in dfs.values():\n",
    "#     ax = d.mean_loss.plot(ax=ax, legend=True)    \n",
    "    \n",
    "# ax.set_xlabel(\"Epochs\")\n",
    "# ax.set_ylabel(\"Mean Loss\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
